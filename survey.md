# Survey of Financial Scam Detection and Agentic AI Systems

## Financial Fraud Detection Platforms

- **Government-FRI System (India)** - The Department of Telecom's Financial Fraud Risk Indicator (FRI) scores mobile numbers by fraud risk to aid banks and UPI apps[\[1\]](https://www.pib.gov.in/PressReleasePage.aspx?PRID=2130249®=3&lang=2#:~:text=What%20is%20the%20%E2%80%9CFinancial%20Fraud,Risk%20Indicator%E2%80%9D). Using multi-source inputs (cybercrime reports, network data, bank intelligence), FRI classifies numbers as "Medium/High/Very High" risk and shares alerts in real time[\[1\]](https://www.pib.gov.in/PressReleasePage.aspx?PRID=2130249®=3&lang=2#:~:text=What%20is%20the%20%E2%80%9CFinancial%20Fraud,Risk%20Indicator%E2%80%9D)[\[2\]](https://www.pib.gov.in/PressReleasePage.aspx?PRID=2130249®=3&lang=2#:~:text=As%20one%20of%20the%20Initial,warning%20before%20allowing%20the%20transaction). Early adopters (e.g. PhonePe) use FRI to block high-risk transactions, reportedly improving prevention with few false alerts[\[2\]](https://www.pib.gov.in/PressReleasePage.aspx?PRID=2130249®=3&lang=2#:~:text=As%20one%20of%20the%20Initial,warning%20before%20allowing%20the%20transaction). _Strength:_ Broad data fusion for proactive warnings. _Limitation:_ Effectiveness depends on quality/timeliness of reported inputs; low-latency sharing is needed[\[1\]](https://www.pib.gov.in/PressReleasePage.aspx?PRID=2130249®=3&lang=2#:~:text=What%20is%20the%20%E2%80%9CFinancial%20Fraud,Risk%20Indicator%E2%80%9D).
- **FraudLens (VNIT Nagpur)** - A prototype "AI-powered fraud detection" platform from a 2025 hackathon, designed for UPI/UPI-like transactions[\[3\]](https://www.financialservices.gov.in/beta/sites/default/files/2025-10/Central-Bank-of-India.pdf#:~:text=%EF%82%B7%20The%20Winning%20team%20VNITx,App%2C%20Machine%20Learning%20Backend%20and). FraudLens includes a mobile app, ML backend, and dashboard. It applies machine learning to features of digital transactions (amounts, patterns, device info) to flag anomalous payments, supporting multiple languages and explainable outputs[\[3\]](https://www.financialservices.gov.in/beta/sites/default/files/2025-10/Central-Bank-of-India.pdf#:~:text=%EF%82%B7%20The%20Winning%20team%20VNITx,App%2C%20Machine%20Learning%20Backend%20and). _Strength:_ Modular design supports integration and compliance; explainable AI aids regulator trust[\[3\]](https://www.financialservices.gov.in/beta/sites/default/files/2025-10/Central-Bank-of-India.pdf#:~:text=%EF%82%B7%20The%20Winning%20team%20VNITx,App%2C%20Machine%20Learning%20Backend%20and). _Limitation:_ As a prototype, performance in real-world, large-scale data and concept drift is untested.
- **SafePay QR (MANIT Bhopal)** - An AI-based mobile solution for QR-code scams[\[4\]](https://www.financialservices.gov.in/beta/sites/default/files/2025-10/Central-Bank-of-India.pdf#:~:text=users%20from%20QR,learning%2C%20steganography%20detection%2C%20and%20behavioral). SafePay analyzes scanned UPI QR codes using deep learning and anomaly detection (e.g. transfer-learning image analysis, steganography check, behavioral heuristics) to classify each QR as Safe/Suspicious/Malicious[\[4\]](https://www.financialservices.gov.in/beta/sites/default/files/2025-10/Central-Bank-of-India.pdf#:~:text=users%20from%20QR,learning%2C%20steganography%20detection%2C%20and%20behavioral). It also crowdsources reports (like a mini-Truecaller) to detect fake QR templates. _Strength:_ Real-time, on-device prevention of QR-based phishing. _Limitation:_ May be evaded by novel or obfuscated QR manipulations beyond training data.
- **VishKill (NIT Rourkela)** - A real-time phone scam detection system[\[5\]](https://www.financialservices.gov.in/beta/sites/default/files/2025-10/Central-Bank-of-India.pdf#:~:text=scam%20detection%20system%20for%20voice,The%20solution%20offers%20an). During a call, its app records short audio chunks and streams them to a server that transcribes and analyzes them using AI. Techniques include voice activity detection, deepfake voice checks, speaker diarization, emotion analysis, and an LLM that assesses conversation content[\[5\]](https://www.financialservices.gov.in/beta/sites/default/files/2025-10/Central-Bank-of-India.pdf#:~:text=scam%20detection%20system%20for%20voice,The%20solution%20offers%20an). The system continuously updates a "scam risk" score as the call proceeds. _Strength:_ Catches scam patterns mid-call and can warn users immediately. _Limitation:_ Requires continuous recording/transcription (privacy issues) and may incur latency; voice/AW generation could still fool it if sophisticated.
- **NPCI / Industry ML Solutions** - NPCI and banks deploy ML on transaction streams. For example, NPCI piloted federated learning combining bank and NPCI data for real-time risk scoring[\[6\]](https://iserveu.in/blog/frm/2025/10/23/rise-of-upi-frauds-iserveus-preventive-approach/#:~:text=,Management%20Module). They also offer tools (e.g. _MuleHunter.AI_) that use ML to profile device IDs, geographic anomalies, and behavioral patterns on each UPI transaction[\[7\]](https://iserveu.in/blog/frm/2025/10/23/rise-of-upi-frauds-iserveus-preventive-approach/#:~:text=,Analytics). Banks and fintechs use rule-and-ML engines to score UPI/IMPS transactions on features (amount, velocity, beneficiary frequency, device trust) and trigger alerts or holds[\[8\]](https://iserveu.in/blog/frm/2025/10/23/rise-of-upi-frauds-iserveus-preventive-approach/#:~:text=,data%2C%20and%20device%20trustworthiness%20indicators). _Strength:_ Leverages large data and adaptive models for live defense. _Limitation:_ Complex ensemble models may lack transparency; risk of high false alerts without careful tuning.
- **Commercial Fraud Systems** - Industry tools (e.g. SAS Fraud Management, IBM Trusteer, ACI Fraud Management, proprietary bank systems) analyze transactions using ML (often ensemble/graph models) and rules. These engines correlate multi-channel data (payments, login behavior, geo) to flag fraud rings[\[9\]](https://www.ijert.org/a-comprehensive-survey-on-machine-learning-techniques-for-upi-and-telecommunication-fraud-detection#:~:text=,data%20and%20structured%20transaction%20attributes). In the Indian context, banks also scan SMS/WhatsApp texts for phishing using NLP, as discussed in industry surveys[\[10\]](https://www.pwc.in/ghost-templates/combating-payments-fraud-in-Indias-digital-payments-landscape.html#:~:text=Additionally%2C%20leveraging%20advanced%20technologies%20such,to%20deter%20fraudulent%20activities%20and). _Strength:_ Proven in financial services, can process thousands of transactions/second. _Limitation:_ Often expensive and tailored to card-payments - legacy systems struggle with real-time UPI flows and evolving scam tactics[\[10\]](https://www.pwc.in/ghost-templates/combating-payments-fraud-in-Indias-digital-payments-landscape.html#:~:text=Additionally%2C%20leveraging%20advanced%20technologies%20such,to%20deter%20fraudulent%20activities%20and)[\[8\]](https://iserveu.in/blog/frm/2025/10/23/rise-of-upi-frauds-iserveus-preventive-approach/#:~:text=,data%2C%20and%20device%20trustworthiness%20indicators).
- **Academic Techniques (ML/NLP)** - Research prototypes apply supervised and unsupervised ML to bank fraud data. Studies note that UPI fraud models focus on transaction attributes (amount, device fingerprint, beneficiary history)[\[11\]](https://www.ijert.org/a-comprehensive-survey-on-machine-learning-techniques-for-upi-and-telecommunication-fraud-detection#:~:text=1,Kavya%20et%20al). Graph and clustering models have been used to detect fraud rings. Some work uses LSTM or transformer models on call transcripts to spot scam intent[\[12\]](https://www.ijert.org/a-comprehensive-survey-on-machine-learning-techniques-for-upi-and-telecommunication-fraud-detection#:~:text=,sequence%20analysis%20%5B11). NLP classifiers are applied to SMS/emails to detect phishing (e.g. keyword spotting, URL blacklists)[\[13\]](https://www.ijraset.com/research-paper/phishing-attack-detection-on-text-messages#:~:text=study%20introduces%20a%20text%20message,comes%20to%20identifying%20phished%20communications). _Strength:_ Continually evolving methods (deep nets, Transformers) adapt to new data. _Limitation:_ Academic models often rely on labeled data; may not account for active adversarial tactics or preserve user privacy.

## Conversational Scam Detection Systems

- **LLM Real-Time Call Scam Detector** - Shen _et al._ (2025) propose a system that transcribes live call audio and runs an LLM to spot scam intent mid-call[\[14\]](https://arxiv.org/abs/2502.03964#:~:text=detection%20technologies%20must%20also%20advance,This). The LLM analyzes conversation context to assess fraudulent intent and can immediately warn the user if a scam is likely[\[14\]](https://arxiv.org/abs/2502.03964#:~:text=detection%20technologies%20must%20also%20advance,This). In tests, this approach balanced precision against recall/timeliness. _Strength:_ Leverages LLM understanding to catch subtle social-engineering cues during calls. _Limitation:_ Requires reliable live transcription and incurs computation delay; false positives could disrupt legitimate calls.
- **SMS/Chat Phishing Detectors** - Many systems classify text messages. For example, "PADSTM" is an academic phishing-text detection prototype that reads SMS content, checks any URLs against a blacklist, and scans for custom scam-related keywords[\[13\]](https://www.ijraset.com/research-paper/phishing-attack-detection-on-text-messages#:~:text=study%20introduces%20a%20text%20message,comes%20to%20identifying%20phished%20communications). It uses classifiers (Random Forest, SVM, Naive Bayes, KNN) trained on labeled SMS. In one evaluation, Random Forest achieved the highest accuracy[\[13\]](https://www.ijraset.com/research-paper/phishing-attack-detection-on-text-messages#:~:text=study%20introduces%20a%20text%20message,comes%20to%20identifying%20phished%20communications)[\[15\]](https://www.ijraset.com/research-paper/phishing-attack-detection-on-text-messages#:~:text=A%20PADSTM%20technique%20to%20identify,The%20best%20method%20for%20detecting). _Strength:_ Simple ML can flag obvious phishing patterns. _Limitation:_ Relies on static keyword lists and known bad URLs; attackers can obfuscate links and language to evade.
- **Unified Spam/Scam Filters** - Some email/SMS spam tools use NLP to detect scam intent (identifying urgency, deceptive phrasing, spoofed sender names). For instance, industry surveys note that advanced filters combine content analysis (NLP) with sender reputation and heuristic rules[\[16\]](https://ceur-ws.org/Vol-2940/paper10.pdf#:~:text=consider%20selective%20parts%20of%20the,in%20detecting%20phishing%20websites%20accurately). Machine learning models (including deep networks) have also been applied to content features (embedding or TF-IDF of message text). _Strength:_ Can catch new textual variants of phishing. _Limitation:_ High variance in language means word-based models can miss cleverly worded scams; also privacy issues when scanning personal messages.
- **Chat/Voice Agents** - Emerging solutions integrate LLMs as a layer in messengers. E.g., prototype chatbots can parse incoming WhatsApp messages or calls and classify them as scams using fine-tuned LLMs or GPT-based classifiers[\[14\]](https://arxiv.org/abs/2502.03964#:~:text=detection%20technologies%20must%20also%20advance,This). This may involve prompting a model to label each message ("scam or not") or to summarize intent. _Strength:_ LLMs can generalize to new phrasings. _Limitation:_ Current LLMs can still hallucinate or misclassify, and require internet connectivity/API access.

## Honeypots and Scambaiting (Adversarial Engagement)

- **AI-driven Scambaiting (AI-in-the-Loop)** - A recent framework uses an LLM to simulate a potential victim and engage scammers in live conversation[\[17\]](https://arxiv.org/html/2509.05362v3#:~:text=In%20this%20paper%2C%20we%20propose,strong%20safety%20and%20privacy%20constraints). It monitors incoming chat/call dialogue, maintains a "scam score," and when a threshold is hit, triggers the LLM agent to reply as a believable target. A utility function selects replies that maximize engagement while minimizing disclosure risk (avoiding revealing real PII)[\[17\]](https://arxiv.org/html/2509.05362v3#:~:text=In%20this%20paper%2C%20we%20propose,strong%20safety%20and%20privacy%20constraints)[\[18\]](https://arxiv.org/html/2509.05362v3#:~:text=At%20runtime%2C%20the%20system%20monitors,and%20adaptation%20in%20real%20time). This delays or derails the scam and collects behavioral intelligence. _Strength:_ Fully automated engagement can waste scammers' time and elicit clues (behavioral patterns, preferences). _Limitation:_ Balancing realism vs. safety is hard; flawed replies could tip off the scammer or accidentally reveal info. The approach is resource-intensive (continuous LLM usage) and raises privacy questions (recording dialogues).
- **LLM Scambaiting Deployment (Cybera)** - An operational system has been evaluated over 5 months interacting with real scammers over email/WhatsApp[\[19\]](https://arxiv.org/html/2509.08493v1#:~:text=This%20paper%20presents%20the%20first,In%20particular%2C%20the). It used ChatGPT to generate "bait" messages from multiple faux personas. The study reported ~2,600 engagements (18,700 messages) with an information disclosure rate (IDR) of ~32% - i.e. a third of conversations yielded sensitive info like bank/mule account details[\[19\]](https://arxiv.org/html/2509.08493v1#:~:text=This%20paper%20presents%20the%20first,In%20particular%2C%20the). The LLM responses had ~70% human acceptance (the operator rarely needed edits). _Strength:_ Demonstrated real-world feasibility: LLM "victims" successfully harvested critical indicators of compromise from scammers[\[19\]](https://arxiv.org/html/2509.08493v1#:~:text=This%20paper%20presents%20the%20first,In%20particular%2C%20the). _Limitation:_ Only ~49% of targets even responded to the initial bait, revealing a "takeoff" challenge[\[19\]](https://arxiv.org/html/2509.08493v1#:~:text=This%20paper%20presents%20the%20first,In%20particular%2C%20the). Also, sustained engagement required human review, and the metrics (IDR, speed) indicate much work is needed to make it reliable at scale.
- **Legacy ScamBots** - Earlier anti-scam bots relied on static scripts. Netsafe's Re:Scam (New Zealand) answered scam emails with predefined templates, and later a 2.0 version began using LLMs to vary victim personas[\[20\]](https://arxiv.org/html/2509.08493v1#:~:text=Recent%20advances%20in%20GenAI%20and,rich%20engagements). Another example is "Lenny," a rudimentary telephone bot playing random recordings to stall phone scammers[\[21\]](https://arxiv.org/html/2509.08493v1#:~:text=Early%20scambaiting%20approaches%20primarily%20relied,due%20to%20their%20static%20designs). These systems _engage_ scammers but generally do not adapt beyond preset content. _Strength:_ Simple and guaranteed safe (no real data at risk). _Limitation:_ Poor adaptability: Re:Scam 1.0's fixed replies quickly repeat, and Lenny's loop can be easily circumvented by savvy scammers. LLM-based updates (Re:Scam 2.0) improve variety[\[20\]](https://arxiv.org/html/2509.08493v1#:~:text=Recent%20advances%20in%20GenAI%20and,rich%20engagements) but still lack true planning or learning.
- **Automated Goal-Driven Agents** - Research prototypes use multiple LLM agents in adversarial self-play. For example, "Bot Wars Evolved" trained two LLM agents (scammer vs. victim) with role-specific objectives and chain-of-thought prompting, producing strategic dialog that mirrored real scams[\[22\]](https://arxiv.org/html/2509.08493v1#:~:text=Charnsethikul%20et%20al.%E2%80%99s%20Puppeteer%C2%A0,that%20mirrored%20real%20scambaiting%20data). These are mostly lab demos. _Strength:_ Demonstrates that an LLM can plan and sustain a scam scenario. _Limitation:_ High complexity and still limited to simulations; no deployed product exists yet.

## Phishing Detection & Intelligence Gathering Systems

- **Multi-Faceted Detectors** - Phishing filters often combine text analysis with external lookups. For instance, one system assigns a risk score by parsing email content (body and subject) and checking URLs against blacklists and search engine results[\[16\]](https://ceur-ws.org/Vol-2940/paper10.pdf#:~:text=consider%20selective%20parts%20of%20the,in%20detecting%20phishing%20websites%20accurately). Modern approaches may also screenshot websites (visual features) or compute lexicon-based phishing scores[\[16\]](https://ceur-ws.org/Vol-2940/paper10.pdf#:~:text=consider%20selective%20parts%20of%20the,in%20detecting%20phishing%20websites%20accurately). _Strength:_ Multi-source checks catch both known URLs and content cues. _Limitation:_ Zero-day phishing sites (not yet in blacklists) can evade static checks, and sophisticated text (images or PDFs) may slip by content scans.
- **IOC Extraction Tools** - Many cybersecurity tools specifically extract Indicators of Compromise from phishing artifacts. For example, platforms like PhishTool or MISP can parse emails or site HTML to pull out suspicious URLs, IPs, domains, email addresses, and embedded data (like hidden phone numbers or UPI IDs). These IOCs feed threat feeds. In scambaiting setups, the conversational bot effectively acts as an IOC extractor: in one study ~32% of interactions yielded financial IOCs (e.g. mule bank account numbers)[\[19\]](https://arxiv.org/html/2509.08493v1#:~:text=This%20paper%20presents%20the%20first,In%20particular%2C%20the). _Strength:_ Automated IOC gathering accelerates blocklisting and investigation. _Limitation:_ Attackers often use single-use domains or obfuscate data, requiring constant feed updates. Human verification is still usually needed to confirm IOC validity.
- **LLM-enhanced Analysis** - Emerging work explores LLMs for phishing intelligence. For example, an LLM can be prompted to highlight phishing intent or extract structured indicators from text[\[19\]](https://arxiv.org/html/2509.08493v1#:~:text=This%20paper%20presents%20the%20first,In%20particular%2C%20the). (The CID analysis above with the scambaiting bot is one example of using an LLM to parse adversary messages.) Though still nascent, such techniques promise to detect nuanced threats or auto-summarize indicators. _Strength:_ Can adapt to new phrasings and languages. _Limitation:_ LLMs may hallucinate or miss low-level anomalies; currently supplement rather than replace rule-based engines.

## Agentic AI Architectures and Frameworks

- **AutoGPT (Open-Source LLM Agent)** - AutoGPT is an autonomous agent framework that uses GPT-4 to decompose goals into sub-tasks, execute them iteratively, and adjust as needed[\[23\]](https://thezvi.substack.com/p/on-autogpt#:~:text=AutoGPT%20uses%20GPT,queue%2C%20which%20it%20then%20prioritizes). It employs plug-ins (e.g. web browsing, file I/O) for tool access and maintains an external memory log of its actions. The agent generates/prioritizes tasks and can self-correct by adding new subtasks when it detects issues[\[23\]](https://thezvi.substack.com/p/on-autogpt#:~:text=AutoGPT%20uses%20GPT,queue%2C%20which%20it%20then%20prioritizes). _Strength:_ Highly flexible and can run multi-step processes without human prompts. _Limitation:_ In practice, early AutoGPT was prone to drift, getting "distracted" from goals or looping[\[23\]](https://thezvi.substack.com/p/on-autogpt#:~:text=AutoGPT%20uses%20GPT,queue%2C%20which%20it%20then%20prioritizes). Its reliance on plugins also means it inherits any limitations or failures of those APIs.
- **LangGraph** - A graph-based multi-agent framework where tasks are modeled as nodes in a workflow graph[\[24\]](https://arxiv.org/html/2508.10146v1#:~:text=match%20at%20L308%20declarative%20orchestration,Along%20similar%20lines%2C%20Semantic). LangGraph nodes are stateful (maintain context memory), enabling agents to follow structured, multi-turn workflows[\[24\]](https://arxiv.org/html/2508.10146v1#:~:text=match%20at%20L308%20declarative%20orchestration,Along%20similar%20lines%2C%20Semantic)[\[25\]](https://arxiv.org/html/2508.10146v1#:~:text=match%20at%20L358%20on%20the,supports%20memory%20through%20conversation%20sessions). For example, one can define a sequence of agents for web search, data extraction, and response composition, with LangGraph ensuring context passes between them. _Strength:_ Facilitates complex pipelines with clear structure and context handoff. _Limitation:_ Not inherently conversational - it focuses on planning. Building a natural multi-turn chat agent requires stitching graph nodes or adding conversation layers manually.
- **Other Frameworks (AutoGen, MetaGPT, CrewAI, etc.)** - Modern LLM frameworks share similar features: they support memory or session state (to handle multi-turn dialog), allow defining persona/role in system prompts, and can call external tools via function APIs. For instance, MetaGPT (by JetBrains) orchestrates multi-agent collaboration, often by having one agent generate code for another. Many include task validation and retry logic (AutoGen has validators, LangGraph has node checks)[\[26\]](https://arxiv.org/html/2508.10146v1#:~:text=frameworks%2C%20AutoGen%2C%20LangGraph%2C%20Agno%2C%20and,defined). _Strength:_ These libraries reduce engineering effort to build agentic workflows. _Limitation:_ They vary widely; none fully solve persona consistency or hallucination. Agents may maintain some persona by hard-coded prompts, but without explicit guardrails they can drift.
- **Self-Correction and Planning** - Agentic frameworks often loop thinking and acting (ReAct-style) or use "reflection" loops. As noted, AutoGPT's design lets it evaluate its own situation and replan[\[23\]](https://thezvi.substack.com/p/on-autogpt#:~:text=AutoGPT%20uses%20GPT,queue%2C%20which%20it%20then%20prioritizes). Similarly, research agents incorporate self-reflection modules to check and correct mistakes. Tools like the OpenAI function calling allow an agent to query precise data (e.g. Python REPL or search engines) during a conversation, effectively extending its reasoning with facts. _Strength:_ Enables dynamic, multi-turn problem solving and continuous improvement. _Limitation:_ These loops add complexity and can still fail silently; there are no perfect safety/guidance protocols, so agents can go off-track.

**Sources:** Academic and industry reports on fraud detection and scambaiting systems[\[3\]](https://www.financialservices.gov.in/beta/sites/default/files/2025-10/Central-Bank-of-India.pdf#:~:text=%EF%82%B7%20The%20Winning%20team%20VNITx,App%2C%20Machine%20Learning%20Backend%20and)[\[14\]](https://arxiv.org/abs/2502.03964#:~:text=detection%20technologies%20must%20also%20advance,This)[\[17\]](https://arxiv.org/html/2509.05362v3#:~:text=In%20this%20paper%2C%20we%20propose,strong%20safety%20and%20privacy%20constraints)[\[19\]](https://arxiv.org/html/2509.08493v1#:~:text=This%20paper%20presents%20the%20first,In%20particular%2C%20the)[\[23\]](https://thezvi.substack.com/p/on-autogpt#:~:text=AutoGPT%20uses%20GPT,queue%2C%20which%20it%20then%20prioritizes); RBI/NPCI/DoT publications and tech blogs[\[1\]](https://www.pib.gov.in/PressReleasePage.aspx?PRID=2130249®=3&lang=2#:~:text=What%20is%20the%20%E2%80%9CFinancial%20Fraud,Risk%20Indicator%E2%80%9D)[\[6\]](https://iserveu.in/blog/frm/2025/10/23/rise-of-upi-frauds-iserveus-preventive-approach/#:~:text=,Management%20Module)[\[10\]](https://www.pwc.in/ghost-templates/combating-payments-fraud-in-Indias-digital-payments-landscape.html#:~:text=Additionally%2C%20leveraging%20advanced%20technologies%20such,to%20deter%20fraudulent%20activities%20and); and prior research on phishing analysis[\[13\]](https://www.ijraset.com/research-paper/phishing-attack-detection-on-text-messages#:~:text=study%20introduces%20a%20text%20message,comes%20to%20identifying%20phished%20communications)[\[16\]](https://ceur-ws.org/Vol-2940/paper10.pdf#:~:text=consider%20selective%20parts%20of%20the,in%20detecting%20phishing%20websites%20accurately). These discuss platform architectures, ML/LLM techniques, and observed strengths/limitations in detail.

[\[1\]](https://www.pib.gov.in/PressReleasePage.aspx?PRID=2130249®=3&lang=2#:~:text=What%20is%20the%20%E2%80%9CFinancial%20Fraud,Risk%20Indicator%E2%80%9D) [\[2\]](https://www.pib.gov.in/PressReleasePage.aspx?PRID=2130249®=3&lang=2#:~:text=As%20one%20of%20the%20Initial,warning%20before%20allowing%20the%20transaction) Press Release:Press Information Bureau

<https://www.pib.gov.in/PressReleasePage.aspx?PRID=2130249®=3&lang=2>

[\[3\]](https://www.financialservices.gov.in/beta/sites/default/files/2025-10/Central-Bank-of-India.pdf#:~:text=%EF%82%B7%20The%20Winning%20team%20VNITx,App%2C%20Machine%20Learning%20Backend%20and) [\[4\]](https://www.financialservices.gov.in/beta/sites/default/files/2025-10/Central-Bank-of-India.pdf#:~:text=users%20from%20QR,learning%2C%20steganography%20detection%2C%20and%20behavioral) [\[5\]](https://www.financialservices.gov.in/beta/sites/default/files/2025-10/Central-Bank-of-India.pdf#:~:text=scam%20detection%20system%20for%20voice,The%20solution%20offers%20an) financialservices.gov.in

<https://www.financialservices.gov.in/beta/sites/default/files/2025-10/Central-Bank-of-India.pdf>

[\[6\]](https://iserveu.in/blog/frm/2025/10/23/rise-of-upi-frauds-iserveus-preventive-approach/#:~:text=,Management%20Module) [\[7\]](https://iserveu.in/blog/frm/2025/10/23/rise-of-upi-frauds-iserveus-preventive-approach/#:~:text=,Analytics) [\[8\]](https://iserveu.in/blog/frm/2025/10/23/rise-of-upi-frauds-iserveus-preventive-approach/#:~:text=,data%2C%20and%20device%20trustworthiness%20indicators) Rise of UPI Frauds: iServeU's Preventive Approach

<https://iserveu.in/blog/frm/2025/10/23/rise-of-upi-frauds-iserveus-preventive-approach/>

[\[9\]](https://www.ijert.org/a-comprehensive-survey-on-machine-learning-techniques-for-upi-and-telecommunication-fraud-detection#:~:text=,data%20and%20structured%20transaction%20attributes) [\[11\]](https://www.ijert.org/a-comprehensive-survey-on-machine-learning-techniques-for-upi-and-telecommunication-fraud-detection#:~:text=1,Kavya%20et%20al) [\[12\]](https://www.ijert.org/a-comprehensive-survey-on-machine-learning-techniques-for-upi-and-telecommunication-fraud-detection#:~:text=,sequence%20analysis%20%5B11) A Comprehensive Survey on Machine Learning Techniques for UPI and Telecommunication Fraud Detection - IJERT

<https://www.ijert.org/a-comprehensive-survey-on-machine-learning-techniques-for-upi-and-telecommunication-fraud-detection>

[\[10\]](https://www.pwc.in/ghost-templates/combating-payments-fraud-in-Indias-digital-payments-landscape.html#:~:text=Additionally%2C%20leveraging%20advanced%20technologies%20such,to%20deter%20fraudulent%20activities%20and) Combating payments fraud in India's digital payments landscape

<https://www.pwc.in/ghost-templates/combating-payments-fraud-in-Indias-digital-payments-landscape.html>

[\[13\]](https://www.ijraset.com/research-paper/phishing-attack-detection-on-text-messages#:~:text=study%20introduces%20a%20text%20message,comes%20to%20identifying%20phished%20communications) [\[15\]](https://www.ijraset.com/research-paper/phishing-attack-detection-on-text-messages#:~:text=A%20PADSTM%20technique%20to%20identify,The%20best%20method%20for%20detecting) Phishing Attack Detection on Text Messages Using Machine Learning Algorithms

<https://www.ijraset.com/research-paper/phishing-attack-detection-on-text-messages>

[\[14\]](https://arxiv.org/abs/2502.03964#:~:text=detection%20technologies%20must%20also%20advance,This) \[2502.03964\] "It Warned Me Just at the Right Moment": Exploring LLM-based Real-time Detection of Phone Scams

<https://arxiv.org/abs/2502.03964>

[\[16\]](https://ceur-ws.org/Vol-2940/paper10.pdf#:~:text=consider%20selective%20parts%20of%20the,in%20detecting%20phishing%20websites%20accurately) Detecting phishing e-mails using Text Mining and features analysis

<https://ceur-ws.org/Vol-2940/paper10.pdf>

[\[17\]](https://arxiv.org/html/2509.05362v3#:~:text=In%20this%20paper%2C%20we%20propose,strong%20safety%20and%20privacy%20constraints) [\[18\]](https://arxiv.org/html/2509.05362v3#:~:text=At%20runtime%2C%20the%20system%20monitors,and%20adaptation%20in%20real%20time) AI-in-the-Loop: Privacy Preserving Real-Time Scam Detection and Conversational Scambaiting by Leveraging LLMs and Federated Learning

<https://arxiv.org/html/2509.05362v3>

[\[19\]](https://arxiv.org/html/2509.08493v1#:~:text=This%20paper%20presents%20the%20first,In%20particular%2C%20the) [\[20\]](https://arxiv.org/html/2509.08493v1#:~:text=Recent%20advances%20in%20GenAI%20and,rich%20engagements) [\[21\]](https://arxiv.org/html/2509.08493v1#:~:text=Early%20scambaiting%20approaches%20primarily%20relied,due%20to%20their%20static%20designs) [\[22\]](https://arxiv.org/html/2509.08493v1#:~:text=Charnsethikul%20et%20al.%E2%80%99s%20Puppeteer%C2%A0,that%20mirrored%20real%20scambaiting%20data) "Send to which account?" Evaluation of an LLM-based Scambaiting System

<https://arxiv.org/html/2509.08493v1>

[\[23\]](https://thezvi.substack.com/p/on-autogpt#:~:text=AutoGPT%20uses%20GPT,queue%2C%20which%20it%20then%20prioritizes) On AutoGPT - by Zvi Mowshowitz - Don't Worry About the Vase

<https://thezvi.substack.com/p/on-autogpt>

[\[24\]](https://arxiv.org/html/2508.10146v1#:~:text=match%20at%20L308%20declarative%20orchestration,Along%20similar%20lines%2C%20Semantic) [\[25\]](https://arxiv.org/html/2508.10146v1#:~:text=match%20at%20L358%20on%20the,supports%20memory%20through%20conversation%20sessions) [\[26\]](https://arxiv.org/html/2508.10146v1#:~:text=frameworks%2C%20AutoGen%2C%20LangGraph%2C%20Agno%2C%20and,defined) Agentic AI Frameworks: Architectures, Protocols, and Design Challenges

<https://arxiv.org/html/2508.10146v1>